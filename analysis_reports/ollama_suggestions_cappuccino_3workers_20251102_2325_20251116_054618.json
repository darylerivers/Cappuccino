[
  {
    "rationale": "Near optimal learning rate and batch size, high gamma for long-term reward discounting.",
    "learning_rate": 0.0001,
    "batch_size": 512,
    "gamma": 0.99,
    "net_dimension": 1536,
    "ppo_epochs": 12,
    "value_loss_coef": 0.75
  },
  {
    "rationale": "Increased exploration with a higher lr_schedule_factor and worker_num, balanced with learning rate.",
    "learning_rate": 5e-05,
    "batch_size": 256,
    "gamma": 0.98,
    "lr_schedule_factor": 0.75,
    "worker_num": 14
  },
  {
    "rationale": "Explores a different range for base parameters with a focus on lr and value_loss_coef.",
    "learning_rate": 0.0002,
    "batch_size": 128,
    "gamma": 0.97,
    "value_loss_coef": 0.5
  }
]