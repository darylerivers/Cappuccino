[
  {
    "rationale": "Higher learning rate for faster convergence, larger batch size to stabilize gradients, and slightly higher gamma for more focus on long-term rewards.",
    "learning_rate": 0.001,
    "batch_size": 1024,
    "gamma": 0.995,
    "net_dimension": 1536,
    "max_grad_norm": 1.0,
    "value_loss_coef": 0.7
  },
  {
    "rationale": "Lower learning rate for more stable convergence, smaller batch size to reduce variance, and slightly lower gamma for less focus on long-term rewards.",
    "learning_rate": 0.0005,
    "batch_size": 256,
    "gamma": 0.985,
    "net_dimension": 1024,
    "max_grad_norm": 0.75,
    "value_loss_coef": 0.6
  },
  {
    "rationale": "Moderate learning rate for a balance between convergence speed and stability, medium batch size for practical training, and gamma in the middle to consider both short-term and long-term rewards.",
    "learning_rate": 0.00075,
    "batch_size": 512,
    "gamma": 0.99,
    "net_dimension": 1280,
    "max_grad_norm": 1.5,
    "value_loss_coef": 0.65
  }
]