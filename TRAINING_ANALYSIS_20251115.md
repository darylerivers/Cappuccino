# Cappuccino Training Analysis - November 15, 2025

## Executive Summary

**Training Performance: EXCELLENT**
- 3,425 trials completed (345 in last 24 hours)
- Best performance: **7.37%** return (Trial #3358)
- Top 10% averaging: **7.02%** return
- GPU: 98% utilization, training efficiently
- Disk space: 444GB available (auto-cleanup active)

---

## Statistical Analysis

### Top 10% Performance (343 trials)

**Return Distribution:**
- **Best:** 7.37%
- **Worst (of top 10%):** 6.71%
- **Average:** 7.02%
- **Standard Deviation:** 0.29%

**Key Finding:** Very tight clustering in top performers indicates we've found a stable optimal region.

### Top 3 Trial Comparison

| Metric | Trial #3358 | Trial #4198 | Trial #2772 |
|--------|-------------|-------------|-------------|
| **Return** | 7.37% | 7.33% | 7.33% |
| **Date** | Nov 13 | Nov 15 | Nov 12 |
| **Duration** | 8 min | 7 min | 8 min |

---

## Critical Parameters Discovered

### üî• HIGH IMPACT PARAMETERS (>30% different from average)

These parameters are DRAMATICALLY different in top performers:

1. **Learning Rate:** 0.000001 (vs avg 0.000022)
   - **93.7% lower than average**
   - Top trials use EXTREMELY slow, stable learning
   - Prevents catastrophic forgetting

2. **Entropy Coefficient:** 0.000032 (vs avg 0.000132)
   - **65% lower than average**
   - Less random exploration, more exploitation
   - Confident in learned strategies

3. **KL Target:** 0.0056 (vs avg 0.0093)
   - **23.3% lower than average**
   - Tighter policy updates, more conservative

4. **Min Cash Reserve:** 0.050 (vs avg 0.074)
   - **29.8% lower than average**
   - More aggressive capital deployment
   - Less cash sitting idle

5. **Volatility Penalty:** 0.003 (vs avg 0.016)
   - **30.4% lower than average**
   - Willing to tolerate volatility for returns

6. **Adam Epsilon:** 0.000004 (vs avg 0.000002)
   - **High precision in optimizer**

### ‚ö° MEDIUM IMPACT PARAMETERS (15-30% different)

7. **Batch Size:** 1 (vs avg 1.42)
   - Online learning (update every step)
   - **18% lower**

8. **Break Step:** 86,667 (vs avg 105,918)
   - Stop training earlier
   - **16.8% lower** - prevents overfitting

9. **Clip Range:** 0.367 (vs avg 0.307)
   - **13.2% higher** - allows larger policy updates

10. **LR Schedule Usage:** 100% (vs avg 79%)
    - **Always use learning rate schedules**
    - Gradual learning rate decay

11. **Concentration Penalty:** 0.093 (vs avg 0.072)
    - **11.7% higher** - more diversified positions

---

## What Makes Champions Win

### The Winning Formula

**Top 3 trials are REMARKABLY consistent:**

| Parameter | Top 3 Variance | Consistency |
|-----------|----------------|-------------|
| Learning Rate | 0.000000 | **IDENTICAL** |
| Gamma | 0.000000 | **IDENTICAL** |
| Batch Size | 0.000000 | **IDENTICAL** |
| Net Dimension | 0.000000 | **IDENTICAL** (1280) |
| Norm Cash Exp | 0.000000 | **IDENTICAL** (-10) |
| Norm Stocks Exp | 0.000000 | **IDENTICAL** (-7) |
| Norm Tech Exp | 0.000000 | **IDENTICAL** (-15) |
| Use LR Schedule | 0.000000 | **IDENTICAL** (Yes) |

**Only 3 parameters vary significantly:**
1. Max Drawdown Penalty (0.02-0.10) - Trial #2772 is outlier
2. Max Grad Norm (0.7-1.6) - Similar outlier pattern
3. PPO Epochs (8-12) - More variation acceptable

---

## Actionable Insights

### What We've Learned

1. **Ultra-Low Learning Rates Win**
   - 94% reduction from population average
   - Slow, stable learning > fast adaptation

2. **Exploitation > Exploration**
   - Low entropy = confident strategies
   - Low volatility penalty = willing to take calculated risks

3. **Conservative Policy Updates**
   - Low KL target = small changes
   - High clip range paradoxically allows controlled flexibility

4. **Network Architecture is Set**
   - Net dimension: 1280 (unanimous)
   - Not 512, not 2048, exactly 1280

5. **Normalization Matters**
   - Cash: 2^-10 = 0.000977
   - Stocks: 2^-7 = 0.0078125
   - Tech: 2^-15 = 0.0000305

---

## Optimization Routes

### Route 1: Exploit Known Winners (RECOMMENDED) ‚≠ê

**Action:** Lock in proven parameters, search nearby space

```python
Fixed parameters:
- learning_rate: 1.0e-6 to 2.0e-6
- batch_size: 1 (online learning)
- gamma: 0.99
- net_dimension: 1280
- entropy_coef: < 0.0001
- kl_target: 0.005-0.006
- min_cash_reserve: 0.05

Search space:
- max_drawdown_penalty: 0.05-0.10
- ppo_epochs: 8-12
- thread_num: 11-14
- worker_num: 11-16
```

**Expected outcome:** 7.5%+ returns in fewer trials

### Route 2: Continue Broad Search (CURRENT)

**Status:** Working well, finding 7.3%+ consistently

**Pros:**
- May discover new optimal regions
- Currently finding good configs every ~50 trials

**Cons:**
- Slower convergence to absolute best

### Route 3: Ensemble Approach

**Action:** Deploy top 5 models simultaneously, aggregate decisions

**Pros:**
- Reduced variance
- More robust to market regime changes

**Cons:**
- Complex implementation
- Needs paper trading infrastructure

---

## Paper Trading Status

### Current Situation

**Status:** ‚ö†Ô∏è **BLOCKED - Technical Issue**

**Progress Made:**
- ‚úÖ Created fail-safe wrapper (auto-restarts on crash)
- ‚úÖ Fixed model file location issues
- ‚úÖ Created `best_trial` pickle from database
- ‚úÖ Exponential backoff restart logic

**Blocking Issue:**
- Technical indicator array size mismatch (22 vs 11)
- Paper trader expects different feature set than training
- Requires code investigation/fix

**Fail-Safe Features Implemented:**
- Unlimited restarts with exponential backoff
- State tracking (restart counts, consecutive failures)
- Automatic model validation before start
- Detailed logging at `logs/paper_trading_failsafe.log`

### Next Steps for Paper Trading

1. **Investigate feature mismatch**
   - Check which technical indicators model expects
   - Align paper trader configuration with training

2. **Alternative: Use validation script**
   - Run `2_validate.py` on best models
   - Confirms performance on held-out data

3. **Deploy when ready**
   - Fail-safe wrapper is ready: `./paper_trading_failsafe.sh`
   - Will auto-restart on any crashes
   - Monitors process health

---

## Training Infrastructure

### Current Status

**Workers:** 3 processes running
- GPU utilization: 98%
- Memory: 3.1GB / 8GB
- Temperature: 59¬∞C (healthy)
- Trial completion: 7-8 minutes each

**Autonomous AI Advisor:**
- 58 analyses completed
- Monitoring every 50 trials
- Latest suggestions focus on:
  - Batch size 512 for stability
  - Gamma 0.99 for long-term rewards
  - Learning rates 0.00005-0.0001

**Disk Management:**
- 444GB available (49% used)
- Auto-cleanup active after each AI test
- Monitors disk space every cycle
- Warns at <50GB, blocks tests at threshold

### Performance Metrics

**Throughput:**
- 345 trials / 24 hours
- 14.4 trials / hour
- ~4.2 minutes per trial (actual)

**Projected Completion:**
- Current: 3,425 trials
- Target: 5,000 trials
- Remaining: 1,575 trials
- **ETA: ~4.5 days**

---

## Recommendations

### Immediate Actions

1. **Keep training at current pace**
   - 3 workers optimal for current setup
   - GPU pinned at 100% (adding 4th worker won't help)

2. **Monitor for 7.5%+ breakthrough**
   - We're finding 7.3% regularly
   - Next milestone: beat 7.37%

3. **Fix paper trading when convenient**
   - Not blocking optimization progress
   - Can validate with `2_validate.py` instead

### Strategic Decisions

**Option A: Continue to 5,000 trials (current plan)**
- Pros: May find even better configs, comprehensive search
- Cons: Diminishing returns likely
- Time: 4.5 more days

**Option B: Switch to focused search now**
- Lock in top parameters, vary only 5-6 dimensions
- Pros: Faster convergence to absolute best
- Cons: May miss undiscovered regions
- Time: 2-3 days to 500 focused trials

**Option C: Declare victory, move to validation**
- 7.37% is strong performance
- Run extensive backtests on best models
- Deploy to paper trading (after fix)
- Time: 1 day setup, ongoing monitoring

---

## Key Insights Summary

### What's Working

1. ‚úÖ **Ultra-low learning rates** (1e-6 range)
2. ‚úÖ **Online learning** (batch size = 1)
3. ‚úÖ **Long-term focus** (gamma = 0.99)
4. ‚úÖ **Network size 1280** (unanimous)
5. ‚úÖ **Low exploration** (low entropy)
6. ‚úÖ **Conservative policy updates** (low KL)
7. ‚úÖ **Aggressive capital deployment** (low cash reserve)
8. ‚úÖ **Tolerates volatility** (low penalty)

### What Doesn't Matter Much

1. ‚ö™ PPO epochs (8-12 all work)
2. ‚ö™ Worker/thread counts (11-16 range fine)
3. ‚ö™ Target/break steps (within reason)

### What to Avoid

1. ‚ùå High learning rates (>0.00001)
2. ‚ùå Large batches (>1)
3. ‚ùå High entropy (>0.0001)
4. ‚ùå Small networks (<1280 dimensions)
5. ‚ùå High cash reserves (>0.10)

---

## Files Created

- `paper_trading_failsafe.sh` - Auto-restart wrapper
- `create_trial_pickle.py` - Generate trial objects from DB
- `TRAINING_ANALYSIS_20251115.md` - This document

**Usage:**
```bash
# When paper trading is fixed:
./paper_trading_failsafe.sh train_results/cwd_tests/trial_3358_1h

# Create trial pickle for any trial:
python create_trial_pickle.py --trial-id 3358 --output-dir train_results/cwd_tests/trial_3358_1h
```

---

**Last Updated:** 2025-11-15 22:10 UTC
**Next Review:** After 3,500 trials (~12 hours)
